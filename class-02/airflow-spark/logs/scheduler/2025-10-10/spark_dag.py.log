[2025-10-10T18:07:00.077+0000] {processor.py:186} INFO - Started process (PID=177) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:07:00.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:07:00.080+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:07:00.079+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:07:00.089+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:07:00.087+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 28, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 263, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_wordcount). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/app']}
[2025-10-10T18:07:00.089+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:07:00.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.038 seconds
[2025-10-10T18:07:30.471+0000] {processor.py:186} INFO - Started process (PID=182) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:07:30.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:07:30.474+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:07:30.474+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:07:30.481+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:07:30.479+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 28, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 263, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_wordcount). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/app']}
[2025-10-10T18:07:30.482+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:07:30.501+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.036 seconds
[2025-10-10T18:08:00.831+0000] {processor.py:186} INFO - Started process (PID=187) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:08:00.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:08:00.834+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:08:00.834+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:08:00.841+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:08:00.839+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 28, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 263, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_wordcount). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/app']}
[2025-10-10T18:08:00.841+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:08:00.860+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.034 seconds
[2025-10-10T18:08:31.177+0000] {processor.py:186} INFO - Started process (PID=192) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:08:31.177+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:08:31.179+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:08:31.178+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:08:31.183+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:08:31.182+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 28, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 263, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_wordcount). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/app']}
[2025-10-10T18:08:31.184+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:08:31.195+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.022 seconds
[2025-10-10T18:08:45.306+0000] {processor.py:186} INFO - Started process (PID=197) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:08:45.306+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:08:45.308+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:08:45.308+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:08:45.314+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:08:45.312+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 28, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 263, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_wordcount). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/app']}
[2025-10-10T18:08:45.314+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:08:45.326+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.023 seconds
[2025-10-10T18:08:46.327+0000] {processor.py:186} INFO - Started process (PID=202) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:08:46.328+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:08:46.330+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:08:46.330+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:08:46.336+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:08:46.334+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 28, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 263, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_wordcount). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/app']}
[2025-10-10T18:08:46.338+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:08:46.352+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.030 seconds
[2025-10-10T18:09:16.737+0000] {processor.py:186} INFO - Started process (PID=207) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:09:16.738+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:09:16.740+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:09:16.740+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:09:16.748+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:09:16.746+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 28, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 263, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_wordcount). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/app']}
[2025-10-10T18:09:16.749+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:09:16.766+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.035 seconds
[2025-10-10T18:09:38.047+0000] {processor.py:186} INFO - Started process (PID=212) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:09:38.048+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:09:38.049+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:09:38.049+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:09:38.055+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:09:38.054+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 5, in <module>
    from airflow.operators.docker import DockerOperator
ModuleNotFoundError: No module named 'airflow.operators.docker'
[2025-10-10T18:09:38.055+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:09:38.069+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.027 seconds
[2025-10-10T18:09:50.147+0000] {processor.py:186} INFO - Started process (PID=217) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:09:50.148+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:09:50.151+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:09:50.150+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:09:50.156+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:09:50.155+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 5, in <module>
    from airflow.operators.docker import DockerOperator
ModuleNotFoundError: No module named 'airflow.operators.docker'
[2025-10-10T18:09:50.157+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:09:50.173+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.032 seconds
[2025-10-10T18:09:52.219+0000] {processor.py:186} INFO - Started process (PID=222) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:09:52.220+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:09:52.221+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:09:52.221+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:09:52.227+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:09:52.226+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 5, in <module>
    from airflow.operators.docker import DockerOperator
ModuleNotFoundError: No module named 'airflow.operators.docker'
[2025-10-10T18:09:52.227+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:09:52.244+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.030 seconds
[2025-10-10T18:10:08.348+0000] {processor.py:186} INFO - Started process (PID=227) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:10:08.349+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:10:08.351+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:10:08.351+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:10:08.358+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:10:08.357+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 5, in <module>
    from airflow.operators.docker import DockerOperator
ModuleNotFoundError: No module named 'airflow.operators.docker'
[2025-10-10T18:10:08.358+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:10:08.375+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.031 seconds
[2025-10-10T18:10:09.371+0000] {processor.py:186} INFO - Started process (PID=232) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:10:09.372+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:10:09.373+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:10:09.373+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:10:09.378+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:10:09.377+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 5, in <module>
    from airflow.operators.docker import DockerOperator
ModuleNotFoundError: No module named 'airflow.operators.docker'
[2025-10-10T18:10:09.378+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:10:09.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.025 seconds
[2025-10-10T18:10:33.461+0000] {processor.py:186} INFO - Started process (PID=177) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:10:33.463+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:10:33.464+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:10:33.464+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:10:33.467+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:10:33.466+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 5, in <module>
    from airflow.operators.docker import DockerOperator
ModuleNotFoundError: No module named 'airflow.operators.docker'
[2025-10-10T18:10:33.468+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:10:33.481+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.023 seconds
[2025-10-10T18:11:02.751+0000] {processor.py:186} INFO - Started process (PID=182) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:11:02.752+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:11:02.753+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:11:02.753+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:11:02.759+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:11:02.758+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 28, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 263, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_wordcount). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/app']}
[2025-10-10T18:11:02.760+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:11:02.773+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.026 seconds
[2025-10-10T18:11:06.797+0000] {processor.py:186} INFO - Started process (PID=187) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:11:06.797+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:11:06.799+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:11:06.799+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:11:06.806+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:11:06.805+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 28, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 263, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_wordcount). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/app']}
[2025-10-10T18:11:06.807+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:11:06.820+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.027 seconds
[2025-10-10T18:11:29.905+0000] {processor.py:186} INFO - Started process (PID=178) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:11:29.906+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:11:29.908+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:11:29.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:11:29.912+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:11:29.911+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 28, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 263, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_wordcount). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/app']}
[2025-10-10T18:11:29.913+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:11:29.925+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.024 seconds
[2025-10-10T18:12:00.151+0000] {processor.py:186} INFO - Started process (PID=183) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:12:00.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:12:00.154+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:12:00.154+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:12:00.161+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:12:00.159+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 28, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 263, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_wordcount). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/app']}
[2025-10-10T18:12:00.161+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:12:00.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.035 seconds
[2025-10-10T18:12:30.441+0000] {processor.py:186} INFO - Started process (PID=188) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:12:30.442+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:12:30.444+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:12:30.444+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:12:30.452+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:12:30.449+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 28, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 263, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_wordcount). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/app']}
[2025-10-10T18:12:30.452+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:12:30.468+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.033 seconds
[2025-10-10T18:13:00.822+0000] {processor.py:186} INFO - Started process (PID=193) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:13:00.822+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:13:00.824+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:13:00.824+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:13:00.832+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:13:00.830+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 28, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 263, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_wordcount). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/app']}
[2025-10-10T18:13:00.832+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:13:00.848+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.032 seconds
[2025-10-10T18:13:31.173+0000] {processor.py:186} INFO - Started process (PID=198) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:13:31.174+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:13:31.176+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:13:31.175+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:13:31.183+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:13:31.181+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 28, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 263, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_wordcount). Invalid arguments were:
**kwargs: {'volumes': ['./jobs:/app']}
[2025-10-10T18:13:31.183+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:13:31.204+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.037 seconds
[2025-10-10T18:13:35.232+0000] {processor.py:186} INFO - Started process (PID=203) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:13:35.233+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:13:35.236+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:13:35.235+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:13:35.248+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:13:35.246+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 28, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 263, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_wordcount). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/jobs:/app']}
[2025-10-10T18:13:35.248+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:13:35.264+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.037 seconds
[2025-10-10T18:13:36.271+0000] {processor.py:186} INFO - Started process (PID=208) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:13:36.274+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:13:36.276+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:13:36.276+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:13:36.284+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:13:36.283+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 28, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 263, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_wordcount). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/jobs:/app']}
[2025-10-10T18:13:36.285+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:13:36.302+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.038 seconds
[2025-10-10T18:14:06.588+0000] {processor.py:186} INFO - Started process (PID=213) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:14:06.588+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:14:06.590+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:14:06.590+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:14:06.595+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:14:06.594+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 28, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 263, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_wordcount). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/jobs:/app']}
[2025-10-10T18:14:06.596+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:14:06.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.026 seconds
[2025-10-10T18:14:24.197+0000] {processor.py:186} INFO - Started process (PID=176) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:14:24.198+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:14:24.199+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:14:24.199+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:14:24.205+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:14:24.204+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 28, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 263, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_wordcount). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/jobs:/app']}
[2025-10-10T18:14:24.206+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:14:24.218+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.026 seconds
[2025-10-10T18:14:54.481+0000] {processor.py:186} INFO - Started process (PID=181) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:14:54.482+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:14:54.484+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:14:54.483+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:14:54.491+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:14:54.489+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 28, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 263, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 938, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: spark_wordcount). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/jobs:/app']}
[2025-10-10T18:14:54.491+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:14:54.506+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.030 seconds
[2025-10-10T18:18:02.474+0000] {processor.py:186} INFO - Started process (PID=176) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:18:02.474+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:18:02.476+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:18:02.476+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:18:02.482+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:18:02.481+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 32, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 270, in __init__
    raise ValueError(msg)
ValueError: Invalid `auto_remove` value True, expected one of 'never', 'success', or 'force'.
[2025-10-10T18:18:02.483+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:18:02.495+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.024 seconds
[2025-10-10T18:18:32.786+0000] {processor.py:186} INFO - Started process (PID=181) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:18:32.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:18:32.788+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:18:32.788+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:18:32.795+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:18:32.793+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 32, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 270, in __init__
    raise ValueError(msg)
ValueError: Invalid `auto_remove` value True, expected one of 'never', 'success', or 'force'.
[2025-10-10T18:18:32.795+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:18:32.812+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.030 seconds
[2025-10-10T18:19:03.124+0000] {processor.py:186} INFO - Started process (PID=186) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:19:03.125+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:19:03.126+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:19:03.126+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:19:03.134+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:19:03.132+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 32, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 270, in __init__
    raise ValueError(msg)
ValueError: Invalid `auto_remove` value True, expected one of 'never', 'success', or 'force'.
[2025-10-10T18:19:03.135+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:19:03.151+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.032 seconds
[2025-10-10T18:19:33.429+0000] {processor.py:186} INFO - Started process (PID=191) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:19:33.430+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:19:33.431+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:19:33.431+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:19:33.437+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:19:33.436+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 32, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 270, in __init__
    raise ValueError(msg)
ValueError: Invalid `auto_remove` value True, expected one of 'never', 'success', or 'force'.
[2025-10-10T18:19:33.438+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:19:33.453+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.028 seconds
[2025-10-10T18:20:19.915+0000] {processor.py:186} INFO - Started process (PID=176) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:20:19.916+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:20:19.918+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:20:19.917+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:20:19.925+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:20:19.924+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 32, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 270, in __init__
    raise ValueError(msg)
ValueError: Invalid `auto_remove` value True, expected one of 'never', 'success', or 'force'.
[2025-10-10T18:20:19.926+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:20:19.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.048 seconds
[2025-10-10T18:20:50.178+0000] {processor.py:186} INFO - Started process (PID=181) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:20:50.178+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:20:50.180+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:20:50.180+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:20:50.187+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:20:50.186+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 32, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 270, in __init__
    raise ValueError(msg)
ValueError: Invalid `auto_remove` value True, expected one of 'never', 'success', or 'force'.
[2025-10-10T18:20:50.188+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:20:50.206+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.033 seconds
[2025-10-10T18:21:20.554+0000] {processor.py:186} INFO - Started process (PID=186) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:21:20.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:21:20.558+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:21:20.557+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:21:20.565+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:21:20.563+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 32, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 270, in __init__
    raise ValueError(msg)
ValueError: Invalid `auto_remove` value True, expected one of 'never', 'success', or 'force'.
[2025-10-10T18:21:20.565+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:21:20.583+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.036 seconds
[2025-10-10T18:21:50.909+0000] {processor.py:186} INFO - Started process (PID=191) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:21:50.910+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:21:50.912+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:21:50.911+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:21:50.920+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:21:50.918+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 32, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 270, in __init__
    raise ValueError(msg)
ValueError: Invalid `auto_remove` value True, expected one of 'never', 'success', or 'force'.
[2025-10-10T18:21:50.920+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:21:50.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.036 seconds
[2025-10-10T18:22:21.239+0000] {processor.py:186} INFO - Started process (PID=196) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:22:21.239+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:22:21.241+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:22:21.241+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:22:21.246+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:22:21.244+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 32, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 270, in __init__
    raise ValueError(msg)
ValueError: Invalid `auto_remove` value True, expected one of 'never', 'success', or 'force'.
[2025-10-10T18:22:21.246+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:22:21.259+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.024 seconds
[2025-10-10T18:22:51.604+0000] {processor.py:186} INFO - Started process (PID=201) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:22:51.609+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:22:51.614+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:22:51.614+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:22:51.621+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:22:51.619+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 32, in <module>
    run_spark_job = DockerOperator(
                    ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py", line 490, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/docker/operators/docker.py", line 270, in __init__
    raise ValueError(msg)
ValueError: Invalid `auto_remove` value True, expected one of 'never', 'success', or 'force'.
[2025-10-10T18:22:51.622+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:22:51.637+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.059 seconds
[2025-10-10T18:23:10.850+0000] {processor.py:186} INFO - Started process (PID=206) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:23:10.851+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:23:10.853+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:23:10.852+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:23:10.879+0000] {processor.py:925} INFO - DAG(s) 'spark_wordcount_in_docker' retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:23:11.016+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:23:11.015+0000] {override.py:1900} INFO - Created Permission View: can read on DAG:spark_wordcount_in_docker
[2025-10-10T18:23:11.022+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:23:11.022+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG:spark_wordcount_in_docker
[2025-10-10T18:23:11.026+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:23:11.026+0000] {override.py:1900} INFO - Created Permission View: can edit on DAG:spark_wordcount_in_docker
[2025-10-10T18:23:11.031+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:23:11.030+0000] {override.py:1900} INFO - Created Permission View: can read on DAG Run:spark_wordcount_in_docker
[2025-10-10T18:23:11.034+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:23:11.034+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG Run:spark_wordcount_in_docker
[2025-10-10T18:23:11.036+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:23:11.036+0000] {override.py:1900} INFO - Created Permission View: can create on DAG Run:spark_wordcount_in_docker
[2025-10-10T18:23:11.040+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:23:11.040+0000] {override.py:1900} INFO - Created Permission View: menu access on DAG Run:spark_wordcount_in_docker
[2025-10-10T18:23:11.040+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:23:11.040+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-10-10T18:23:11.047+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:23:11.047+0000] {dag.py:3262} INFO - Creating ORM DAG for spark_wordcount_in_docker
[2025-10-10T18:23:11.054+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:23:11.054+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_wordcount_in_docker to 2025-10-09 00:00:00+00:00, run_after=2025-10-10 00:00:00+00:00
[2025-10-10T18:23:11.065+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.218 seconds
[2025-10-10T18:23:33.106+0000] {processor.py:186} INFO - Started process (PID=211) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:23:33.108+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:23:33.110+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:23:33.110+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:23:33.124+0000] {processor.py:925} INFO - DAG(s) 'spark_wordcount_in_docker' retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:23:33.137+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:23:33.137+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-10-10T18:23:33.152+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:23:33.152+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_wordcount_in_docker to 2025-10-09 00:00:00+00:00, run_after=2025-10-10 00:00:00+00:00
[2025-10-10T18:23:33.165+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.064 seconds
[2025-10-10T18:23:54.498+0000] {processor.py:186} INFO - Started process (PID=176) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:23:54.499+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:23:54.500+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:23:54.499+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:23:54.508+0000] {processor.py:925} INFO - DAG(s) 'spark_wordcount_in_docker' retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:23:54.523+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:23:54.523+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-10-10T18:23:54.536+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:23:54.536+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_wordcount_in_docker to 2025-10-09 00:00:00+00:00, run_after=2025-10-10 00:00:00+00:00
[2025-10-10T18:23:54.547+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.054 seconds
[2025-10-10T18:24:24.787+0000] {processor.py:186} INFO - Started process (PID=187) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:24:24.788+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:24:24.790+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:24:24.790+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:24:24.803+0000] {processor.py:925} INFO - DAG(s) 'spark_wordcount_in_docker' retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:24:24.830+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:24:24.830+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-10-10T18:24:24.844+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:24:24.844+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_wordcount_in_docker to 2025-10-10 00:00:00+00:00, run_after=2025-10-11 00:00:00+00:00
[2025-10-10T18:24:24.854+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.073 seconds
[2025-10-10T18:24:35.882+0000] {processor.py:186} INFO - Started process (PID=192) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:24:35.883+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:24:35.885+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:24:35.885+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:24:35.903+0000] {processor.py:925} INFO - DAG(s) 'spark_wordcount_in_docker' retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:24:35.928+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:24:35.928+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-10-10T18:24:35.947+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:24:35.947+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_wordcount_in_docker to 2025-10-10 00:00:00+00:00, run_after=2025-10-11 00:00:00+00:00
[2025-10-10T18:24:35.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.084 seconds
[2025-10-10T18:25:06.171+0000] {processor.py:186} INFO - Started process (PID=197) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:25:06.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:25:06.174+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:25:06.174+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:25:06.187+0000] {processor.py:925} INFO - DAG(s) 'spark_wordcount_in_docker' retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:25:06.209+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:25:06.209+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-10-10T18:25:06.223+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:25:06.223+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_wordcount_in_docker to 2025-10-10 00:00:00+00:00, run_after=2025-10-11 00:00:00+00:00
[2025-10-10T18:25:06.233+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.066 seconds
[2025-10-10T18:25:36.574+0000] {processor.py:186} INFO - Started process (PID=202) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:25:36.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:25:36.577+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:25:36.577+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:25:36.587+0000] {processor.py:925} INFO - DAG(s) 'spark_wordcount_in_docker' retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:25:36.606+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:25:36.605+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-10-10T18:25:36.621+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:25:36.620+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_wordcount_in_docker to 2025-10-10 00:00:00+00:00, run_after=2025-10-11 00:00:00+00:00
[2025-10-10T18:25:36.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.061 seconds
[2025-10-10T18:26:06.948+0000] {processor.py:186} INFO - Started process (PID=207) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:26:06.949+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:26:06.952+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:26:06.951+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:26:06.969+0000] {processor.py:925} INFO - DAG(s) 'spark_wordcount_in_docker' retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:26:06.993+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:26:06.993+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-10-10T18:26:07.007+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:26:07.007+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_wordcount_in_docker to 2025-10-10 00:00:00+00:00, run_after=2025-10-11 00:00:00+00:00
[2025-10-10T18:26:07.018+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.077 seconds
[2025-10-10T18:26:37.334+0000] {processor.py:186} INFO - Started process (PID=212) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:26:37.335+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:26:37.336+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:26:37.336+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:26:37.346+0000] {processor.py:925} INFO - DAG(s) 'spark_wordcount_in_docker' retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:26:37.364+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:26:37.364+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-10-10T18:26:37.378+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:26:37.378+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_wordcount_in_docker to 2025-10-10 00:00:00+00:00, run_after=2025-10-11 00:00:00+00:00
[2025-10-10T18:26:37.390+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.060 seconds
[2025-10-10T18:27:07.652+0000] {processor.py:186} INFO - Started process (PID=220) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:27:07.652+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:27:07.653+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:27:07.653+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:27:07.664+0000] {processor.py:925} INFO - DAG(s) 'spark_wordcount_in_docker' retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:27:07.681+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:27:07.681+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-10-10T18:27:07.694+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:27:07.694+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_wordcount_in_docker to 2025-10-10 00:00:00+00:00, run_after=2025-10-11 00:00:00+00:00
[2025-10-10T18:27:07.707+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.059 seconds
[2025-10-10T18:27:38.036+0000] {processor.py:186} INFO - Started process (PID=225) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:27:38.037+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:27:38.039+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:27:38.039+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:27:38.052+0000] {processor.py:925} INFO - DAG(s) 'spark_wordcount_in_docker' retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:27:38.071+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:27:38.071+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-10-10T18:27:38.087+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:27:38.087+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_wordcount_in_docker to 2025-10-10 00:00:00+00:00, run_after=2025-10-11 00:00:00+00:00
[2025-10-10T18:27:38.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.067 seconds
[2025-10-10T18:28:08.384+0000] {processor.py:186} INFO - Started process (PID=230) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:28:08.385+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:28:08.387+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:28:08.386+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:28:08.396+0000] {processor.py:925} INFO - DAG(s) 'spark_wordcount_in_docker' retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:28:08.416+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:28:08.415+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-10-10T18:28:08.431+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:28:08.431+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_wordcount_in_docker to 2025-10-10 00:00:00+00:00, run_after=2025-10-11 00:00:00+00:00
[2025-10-10T18:28:08.442+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.061 seconds
[2025-10-10T18:28:38.741+0000] {processor.py:186} INFO - Started process (PID=235) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:28:38.742+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:28:38.745+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:28:38.745+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:28:38.758+0000] {processor.py:925} INFO - DAG(s) 'spark_wordcount_in_docker' retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:28:38.779+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:28:38.778+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-10-10T18:28:38.794+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:28:38.794+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_wordcount_in_docker to 2025-10-10 00:00:00+00:00, run_after=2025-10-11 00:00:00+00:00
[2025-10-10T18:28:38.804+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.068 seconds
[2025-10-10T18:29:09.039+0000] {processor.py:186} INFO - Started process (PID=240) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:29:09.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:29:09.041+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:29:09.041+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:29:09.051+0000] {processor.py:925} INFO - DAG(s) 'spark_wordcount_in_docker' retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:29:09.068+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:29:09.068+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-10-10T18:29:09.082+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:29:09.082+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_wordcount_in_docker to 2025-10-10 00:00:00+00:00, run_after=2025-10-11 00:00:00+00:00
[2025-10-10T18:29:09.094+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.058 seconds
[2025-10-10T18:29:39.334+0000] {processor.py:186} INFO - Started process (PID=245) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:29:39.335+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:29:39.336+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:29:39.336+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:29:39.346+0000] {processor.py:925} INFO - DAG(s) 'spark_wordcount_in_docker' retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:29:39.364+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:29:39.364+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-10-10T18:29:39.378+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:29:39.378+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_wordcount_in_docker to 2025-10-10 00:00:00+00:00, run_after=2025-10-11 00:00:00+00:00
[2025-10-10T18:29:39.391+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.061 seconds
[2025-10-10T18:30:09.718+0000] {processor.py:186} INFO - Started process (PID=250) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:30:09.719+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:30:09.721+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:30:09.721+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:30:09.732+0000] {processor.py:925} INFO - DAG(s) 'spark_wordcount_in_docker' retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:30:09.752+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:30:09.752+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-10-10T18:30:09.765+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:30:09.765+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_wordcount_in_docker to 2025-10-10 00:00:00+00:00, run_after=2025-10-11 00:00:00+00:00
[2025-10-10T18:30:09.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.059 seconds
[2025-10-10T18:30:40.057+0000] {processor.py:186} INFO - Started process (PID=255) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:30:40.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:30:40.060+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:30:40.060+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:30:40.072+0000] {processor.py:925} INFO - DAG(s) 'spark_wordcount_in_docker' retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:30:40.092+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:30:40.092+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-10-10T18:30:40.108+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:30:40.108+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_wordcount_in_docker to 2025-10-10 00:00:00+00:00, run_after=2025-10-11 00:00:00+00:00
[2025-10-10T18:30:40.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.066 seconds
[2025-10-10T18:31:10.531+0000] {processor.py:186} INFO - Started process (PID=260) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:31:10.531+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:31:10.534+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:31:10.533+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:31:10.545+0000] {processor.py:925} INFO - DAG(s) 'spark_wordcount_in_docker' retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:31:10.565+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:31:10.565+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-10-10T18:31:10.579+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:31:10.579+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_wordcount_in_docker to 2025-10-10 00:00:00+00:00, run_after=2025-10-11 00:00:00+00:00
[2025-10-10T18:31:10.590+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.064 seconds
[2025-10-10T18:31:40.904+0000] {processor.py:186} INFO - Started process (PID=265) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:31:40.905+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:31:40.908+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:31:40.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:31:40.924+0000] {processor.py:925} INFO - DAG(s) 'spark_wordcount_in_docker' retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:31:40.942+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:31:40.941+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-10-10T18:31:40.954+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:31:40.954+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_wordcount_in_docker to 2025-10-10 00:00:00+00:00, run_after=2025-10-11 00:00:00+00:00
[2025-10-10T18:31:40.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.065 seconds
[2025-10-10T18:32:11.297+0000] {processor.py:186} INFO - Started process (PID=270) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:32:11.298+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:32:11.303+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:32:11.303+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:32:11.315+0000] {processor.py:925} INFO - DAG(s) 'spark_wordcount_in_docker' retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:32:11.334+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:32:11.334+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-10-10T18:32:11.350+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:32:11.350+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_wordcount_in_docker to 2025-10-10 00:00:00+00:00, run_after=2025-10-11 00:00:00+00:00
[2025-10-10T18:32:11.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.088 seconds
[2025-10-10T18:32:41.601+0000] {processor.py:186} INFO - Started process (PID=275) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:32:41.601+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:32:41.603+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:32:41.603+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:32:41.612+0000] {processor.py:925} INFO - DAG(s) 'spark_wordcount_in_docker' retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:32:41.630+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:32:41.629+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-10-10T18:32:41.644+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:32:41.643+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_wordcount_in_docker to 2025-10-10 00:00:00+00:00, run_after=2025-10-11 00:00:00+00:00
[2025-10-10T18:32:41.654+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.057 seconds
[2025-10-10T18:33:11.963+0000] {processor.py:186} INFO - Started process (PID=280) to work on /opt/airflow/dags/spark_dag.py
[2025-10-10T18:33:11.964+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2025-10-10T18:33:11.966+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:33:11.966+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:33:11.978+0000] {processor.py:925} INFO - DAG(s) 'spark_wordcount_in_docker' retrieved from /opt/airflow/dags/spark_dag.py
[2025-10-10T18:33:11.998+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:33:11.997+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-10-10T18:33:12.012+0000] {logging_mixin.py:190} INFO - [2025-10-10T18:33:12.011+0000] {dag.py:4180} INFO - Setting next_dagrun for spark_wordcount_in_docker to 2025-10-10 00:00:00+00:00, run_after=2025-10-11 00:00:00+00:00
[2025-10-10T18:33:12.020+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_dag.py took 0.062 seconds
